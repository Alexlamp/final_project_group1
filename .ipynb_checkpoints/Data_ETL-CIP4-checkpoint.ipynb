{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import timeit\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_password = str(input(\"Please provide your sql password : \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dbname =  str(input(\"Please provide your sql Data Base name or press ENTER, default 'Almost_Best_airline' :\"))\n",
    "if target_dbname == '':\n",
    "    target_dbname = 'Almost_Best_airline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_name_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_list_update(dataframe_list, dataframe):\n",
    "    dataframe_list.append(dataframe)\n",
    "    \n",
    "    return dataframe_list \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Airplane delay data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def airplane_data():\n",
    "    try:\n",
    "        dataframe_list = []\n",
    "        path_to_file0 = os.path.join('Resources','DelayedFlights.csv')\n",
    "        airline_delayed_df = pd.read_csv(path_to_file0)\n",
    "        airline_delayed_df.head(2)\n",
    "        \n",
    "        #removing irrelevant rows\n",
    "        arline_delayed_cln=airline_delayed_df.drop(['DepTime','CRSDepTime','ArrTime','CRSArrTime','FlightNum','TailNum','ActualElapsedTime',\n",
    "                                            'CRSElapsedTime','AirTime','TaxiIn','TaxiOut'],1)\n",
    "        arline_delayed_cln = arline_delayed_cln.drop(arline_delayed_cln.columns[0], axis =1)\n",
    "        \n",
    "        #removing all rows with nan in carrier delay\n",
    "        arline_delayed_cln = arline_delayed_cln.dropna(subset = ['CarrierDelay'])\n",
    "        \n",
    "        #dropping all delays not related to carrier delay\n",
    "        arline_delayed_cln = arline_delayed_cln[(arline_delayed_cln[\"WeatherDelay\"] == 0) & (arline_delayed_cln[\"CarrierDelay\"] >= 0)]\n",
    "        arline_delayed_cln = arline_delayed_cln[(arline_delayed_cln[\"NASDelay\"] == 0) & (arline_delayed_cln[\"CarrierDelay\"] >= 0)]\n",
    "        arline_delayed_cln = arline_delayed_cln[(arline_delayed_cln[\"SecurityDelay\"] == 0) & (arline_delayed_cln[\"CarrierDelay\"] >= 0)]\n",
    "        \n",
    "        #dropping unnecessary rows\n",
    "        arline_delayed_cln = arline_delayed_cln.drop(['DayOfWeek','LateAircraftDelay','SecurityDelay','NASDelay','WeatherDelay','Origin','Dest', 'Cancelled', 'Diverted','CancellationCode'],1)\n",
    "        \n",
    "        #dropping missing carrier\n",
    "        arline_delayed_cln = arline_delayed_cln.dropna(subset = ['UniqueCarrier'])\n",
    "        \n",
    "        #converting 3 data columns to one day time column\n",
    "        arline_delayed_cln['Date'] = pd.to_datetime(dict(year=arline_delayed_cln.Year, month=arline_delayed_cln.Month, day=arline_delayed_cln.DayofMonth))\n",
    "        arline_delayed_cln = arline_delayed_cln.drop(['Year','Month','DayofMonth'],1)\n",
    "        \n",
    "        print('ok1')\n",
    "        \n",
    "        display(arline_delayed_cln.head(10))\n",
    "        display(arline_delayed_cln.tail(10))\n",
    "        \n",
    "        #checking NaN\n",
    "        for column in arline_delayed_cln:\n",
    "            null = arline_delayed_cln[column].isnull().sum()\n",
    "            print(f'{column} has {null} missing values')\n",
    "        \n",
    "        print('ok2')\n",
    "        \n",
    "        #changing year column to date time format             \n",
    "        dealay_time_year = arline_delayed_cln\n",
    "        dealay_time_year['year'] = dealay_time_year['Date'].dt.year\n",
    "        dealay_time_year.dtypes\n",
    "        \n",
    "        print('ok3')\n",
    "            \n",
    "        #creating df with average arrivial delay for each carrier\n",
    "        arrival_delay = arline_delayed_cln[['UniqueCarrier','ArrDelay','Date']].copy()\n",
    "        arrival_delay['month'] = arrival_delay['Date'].dt.month\n",
    "        arrival_delay = arrival_delay.drop('Date',1)\n",
    "        print('\\n arrival_delay')\n",
    "        display(arrival_delay)\n",
    "        \n",
    "        print('ok4')\n",
    "        \n",
    "        arrival_delay_gb = arrival_delay.groupby(['month','UniqueCarrier']).mean()\n",
    "        arrival_delay_gb.reset_index(level=0, inplace=True)\n",
    "        arrival_delay_gb.reset_index(level=0, inplace=True)\n",
    "        \n",
    "        print('ok5')\n",
    "         \n",
    "        \n",
    "        #creating airline list that will be used to cycle over arrival delay df\n",
    "        airline_list_df = arrival_delay_gb.groupby(['UniqueCarrier']).mean()\n",
    "        airline_list_df.reset_index(level=0, inplace=True)\n",
    "        airline_list = airline_list_df['UniqueCarrier'].tolist()\n",
    "        \n",
    "\n",
    "        arrival_delay_avg_per_month = arrival_delay.groupby(['month']).mean()\n",
    "        \n",
    "        \n",
    "        print('ok6')\n",
    "            \n",
    "        #display(arr_delay_avg_per_month)\n",
    "        for airline in airline_list:\n",
    "            arrival_delay_transition = arrival_delay.loc[(arrival_delay[\"UniqueCarrier\"] == airline)]\n",
    "            arrival_delay_avg_per_month[airline] = arrival_delay_transition.groupby(['month']).mean()\n",
    "                \n",
    "        arrival_delay_avg_per_month = arrival_delay_avg_per_month.drop('ArrDelay',1)\n",
    "        arrival_delay_avg_per_month = arrival_delay_avg_per_month.fillna(0)\n",
    "        print('\\n arrival_delay_avg_per_month')\n",
    "        display(arrival_delay_avg_per_month)\n",
    "        \n",
    "        print('ok7')\n",
    "            \n",
    "        for airline in airline_list:\n",
    "            ax = arrival_delay_avg_per_month[airline].plot(lw=2, markersize=50, figsize = (12,4), title = \"Average delay per month\")\n",
    "            plt.legend(airline_list, loc='center right')\n",
    "        \n",
    "        print('ok8')\n",
    "        \n",
    "        avg_delay = arline_delayed_cln.groupby(['UniqueCarrier']).mean()\n",
    "        delay_sum = arline_delayed_cln.groupby(['UniqueCarrier']).sum()\n",
    "        delay_count = arline_delayed_cln.groupby(['UniqueCarrier']).count()\n",
    "        airline_delay_stat = avg_delay.merge(delay_sum, left_index = True, right_index = True)\n",
    "        \n",
    "        print('ok9')\n",
    "            \n",
    "        airline_delay_stat = airline_delay_stat.rename(columns={'ArrDelay_x' : 'ArrDelay_avg', 'DepDelay_x' : 'DepDelay_avg', 'CarrierDelay_x' : 'CarrierDelay_avg',\n",
    "                                              'Distance_x' : 'Distance_avg', 'ArrDelay_y' : 'ArrDelay_sum', 'DepDelay_y' : 'DepDelay_sum', 'Distance_y' : 'Distance_sum', \n",
    "                                              'CarrierDelay_y' : 'CarrierDelay_sum','year_x' : 'year' })\n",
    "        \n",
    "        print('ok10')\n",
    "        \n",
    "        airline_delay_stat = airline_delay_stat.drop('year_y',1)\n",
    "        print('\\n airline_delay_stat')\n",
    "        display(airline_delay_stat)\n",
    "        \n",
    "        print('ok11')\n",
    "        \n",
    "        airline_delay_stat_db = airline_delay_stat.copy()\n",
    "        airline_delay_stat_db['unique_carrier'] = airline_delay_stat_db.index\n",
    "        \n",
    "         \n",
    "        print(\"\\n airline_delay_stat_db\")\n",
    "        display(airline_delay_stat_db)\n",
    "        \n",
    "        print('ok12')\n",
    "        \n",
    "#         dataframe_list = dataframe_list.append(airline_delay_stat_db)\n",
    "#         dataframe_list = dataframe_list.append(airline_delay_stat)\n",
    "        \n",
    "    except:\n",
    "        print('There was an issue', sys.exc_info()[0], \"probably you didn't load the file DelayedFlights.csv to resources folder\")\n",
    "        print\n",
    " \n",
    "    return  airline_delay_stat_db,airline_delay_stat\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    airline_delay_stat_db,airline_delay_stat = airplane_data()\n",
    "    dataframe_list_update(dataframe_list,airline_delay_stat_db)\n",
    "    dataframe_dict['airline_delay_stat_db'] = airline_delay_stat_db\n",
    "    \n",
    "except:\n",
    "    print('Delay csv file not loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe_list.append(airline_delay_stat_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SFO Data\n",
    "### SFO data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file1 = os.path.join('Resources','SFO_Landing_statistics.csv')\n",
    "sfo_landing_statistics = pd.read_csv(path_to_file1)\n",
    "sfo_landing_statistics.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file2 = os.path.join('Resources','SFO_Passanger_statistics.csv')\n",
    "sfo_passanger_statistics = pd.read_csv(path_to_file2)\n",
    "sfo_passanger_statistics.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking number of missing data\n",
    "for column in sfo_landing_statistics: \n",
    "    null_nr = sfo_landing_statistics[column].isnull().sum()\n",
    "    print(f'{column} has {null_nr} missing data' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking number of missing data\n",
    "for column in sfo_passanger_statistics: \n",
    "    null_nr = sfo_passanger_statistics[column].isnull().sum()\n",
    "    print(f'{column} has {null_nr} missing data' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only missig data are in columns that are useles for the analysis.\n",
    "#Aircraft version is not not necessary for comparison with airlien fleet data base, we only need brand and model\n",
    "#missing data IATA code kept for now\n",
    "#removing columns: Operating Airline, Operating Airline IATA Code (those are just carriers not beneficient)\n",
    "#removing column aircraft version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_cln(data_frame):\n",
    "        data_frame = data_frame.drop(['Operating Airline','Operating Airline IATA Code'],1)\n",
    "        #data_frame = data_frame.dropna(subset=['Aircraft Manufacturer'])\n",
    "        return data_frame\n",
    "\n",
    "def date_cln(data_frame):\n",
    "    data_frame['Activity Period'] = data_frame['Activity Period'].apply(lambda dt: pd.to_datetime(dt, format='%Y%m', errors='coerce'))\n",
    "\n",
    "    return data_frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfo_passanger_statistics = sfo_passanger_statistics.drop(['Terminal','Boarding Area'],1)\n",
    "sfo_landing_statistics = sfo_landing_statistics.drop(['Aircraft Body Type','Aircraft Version'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning SFO_Landing_statistics_df\n",
    "sfo_landing_statistics = name_cln(sfo_landing_statistics)\n",
    "sfo_landing_statistics = date_cln(sfo_landing_statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #cleaning SFO_Passanger_statistics_df\n",
    "SFO_Passanger_statistics_df = name_cln(sfo_passanger_statistics)\n",
    "SFO_Passanger_statistics_df = date_cln(sfo_passanger_statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(sfo_landing_statistics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfo_landing_statistics = sfo_landing_statistics.drop_duplicates()\n",
    "sfo_landing_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(SFO_Passanger_statistics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfo_landing_statistics = sfo_landing_statistics[234:]\n",
    "sfo_landing_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_list_update(dataframe_list,sfo_landing_statistics)\n",
    "dataframe_dict['sfo_landing_statistics']=sfo_landing_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking columns of sfo_landing_statistics df\n",
    "sfo_landing_statistics.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking columns of sfo_passanger_statistics df\n",
    "sfo_passanger_statistics.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#updating dataframe list\n",
    "\n",
    "dataframe_list_update(dataframe_list,sfo_passanger_statistics)\n",
    "dataframe_dict['sfo_passanger_statistics']=sfo_passanger_statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joined air traffic at SFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging 2 main data frames into 1 based on data stamp \n",
    "#cut landinf df [234:0], join on index and compare the columns, drop if columns are not the same\n",
    "# df  = df[df[1]==df[2]]\n",
    "sfo_data_df = pd.merge(sfo_passanger_statistics,sfo_landing_statistics[[\"Activity Period\",'Published Airline IATA Code',\n",
    "                                                                        'Landing Aircraft Type','Landing Count',\n",
    "                                                                       'Total Landed Weight']], how = 'left',on=[\"Activity Period\", \"Published Airline IATA Code\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfo_data_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfo_data_df = sfo_data_df.dropna()\n",
    "sfo_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keeping only data with overlaapinf airline code\n",
    "#sfo_data_df = sfo_data_df[sfo_data_df['Published Airline IATA Code_x'] == sfo_data_df['Published Airline IATA Code_y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sfo_data_df = date_cln(sfo_data_df)\n",
    "sfo_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sfo_data_df['Total Landed Weight']=sfo_data_df['Total Landed Weight'].drop_duplicates()\n",
    "sfo_data_df = sfo_data_df.drop_duplicates(subset='Total Landed Weight')\n",
    "#sfo_data_df = sfo_data_df.dropna()\n",
    "sfo_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#can use grup by max landing count and airline and then drop index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfo_data_filtered= sfo_data_df.groupby(['Landing Count','Published Airline IATA Code','Published Airline',\"Passenger Count\",'GEO Summary','Price Category Code','Landing Aircraft Type','Activity Period','Total Landed Weight'], as_index = False).sum()\n",
    "sfo_data_filtered = sfo_data_filtered.drop(['Operating Airline','Operating Airline IATA Code', 'Activity Type Code'],1)\n",
    "sfo_data_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfo_data_filtered = sfo_data_filtered.drop_duplicates(subset = 'Passenger Count',keep = 'first')\n",
    "sfo_data_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfo_data_filtered = sfo_data_filtered.sort_values(by = ['Activity Period', 'Published Airline IATA Code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfo_data_columns = sfo_data_filtered.dtypes.index.to_list()\n",
    "sfo_data_columns = ['Activity Period','Published Airline IATA Code','Published Airline','Landing Count','Passenger Count',\n",
    " 'Total Landed Weight','GEO Summary','Price Category Code','Landing Aircraft Type', 'GEO Region']\n",
    "sfo_data_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfo_data_filtered = sfo_data_filtered[sfo_data_columns]\n",
    "sfo_data_filtered = sfo_data_filtered.reset_index()\n",
    "sfo_data_filtered = sfo_data_filtered.drop('index',1)\n",
    "sfo_data_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in sfo_data_filtered: \n",
    "    unique_v = sfo_data_filtered[column].unique()\n",
    "    print(f'{column} has unique data {unique_v} ' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing Nan\n",
    "sfo_data_filtered = sfo_data_filtered.dropna()\n",
    "sfo_data_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for remaning duplicates\n",
    "for column in sfo_data_filtered:\n",
    "    null = sfo_data_filtered[column].isnull().sum()\n",
    "    print(f'{column} has {null} missing values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining flight_factor: the number that represents the passager, freight and combo flights\n",
    "#It represents the normalized amount of cargo that is carried by a single flight of a specific flight type\n",
    "\n",
    "sfo_data_weight = sfo_data_filtered.groupby(['Published Airline', 'Landing Aircraft Type']).sum()\n",
    "display(sfo_data_weight.head(10))\n",
    "\n",
    "\n",
    "#for each flight type the fligh factor is calculated as follosws:\n",
    "#total weight per total landing count flight divided by 1000,000. \n",
    "sfo_data_weight = sfo_data_filtered.groupby(['Landing Aircraft Type']).sum()\n",
    "display(sfo_data_weight)\n",
    "\n",
    "\n",
    "#i use to classify the passanger vs freight and combo uffff\n",
    "sfo_data_weight['factor'] = (sfo_data_weight['Total Landed Weight']/sfo_data_weight['Landing Count'])/1000000\n",
    "display(sfo_data_weight)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfo_data_w_flight_class = sfo_data_filtered.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating ist of flight types\n",
    "flight_types = sfo_data_weight.index.to_list()\n",
    "flight_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing flight type by factor equivalent\n",
    "for flight_type in flight_types:\n",
    "    sfo_data_w_flight_class.loc[sfo_data_w_flight_class['Landing Aircraft Type']==flight_type,'Landing Aircraft Type']=sfo_data_weight['factor'][flight_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfo_data_w_flight_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing price classification of airlines based on Alex Lamp feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_to_file4 = os.path.join('Resources','airline_class.csv')\n",
    "# airline_class = pd.read_csv(path_to_file4)\n",
    "# airline_class = airline_class.rename(columns={'airline_name':'Published Airline'})\n",
    "\n",
    "# #making list of Boutique and low cost\n",
    "# boutique_class = airline_class.loc[airline_class['class'] == 'Boutique']['Published Airline'].to_list()\n",
    "# low_cost_class = airline_class.loc[airline_class['class'] == 'Low Cost Carrier']['Published Airline'].to_list()  \n",
    "\n",
    "boutique_class = ['All Nippon Airways','Cathay Pacific', 'Emirates', 'Etihad Airways','Japan Airlines','Singapore Airlines']\n",
    "low_cost_class = ['Aer Lingus','Allegiant Air','Frontier Airlines','JetBlue Airways','Spirit Airlines']\n",
    "\n",
    "#substituting proper price category to each airline\n",
    "for airline in low_cost_class:\n",
    "    sfo_data_w_flight_class.loc[sfo_data_w_flight_class['Published Airline'] == airline,'Price Category Code'] = 0.7 #'Low cost'\n",
    "    \n",
    "for airline in boutique_class:\n",
    "    sfo_data_w_flight_class.loc[sfo_data_w_flight_class['Published Airline'] == airline,'Price Category Code'] = 1.3 #'Boutique'\n",
    "    \n",
    "sfo_data_w_flight_class.loc[sfo_data_w_flight_class['Price Category Code'] == 'Low Fare','Price Category Code'] = 0.7 #'Low cost'\n",
    "\n",
    "sfo_data_w_flight_class.loc[sfo_data_w_flight_class['Price Category Code'] == 'Other','Price Category Code'] = 1 #'Legacy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleanning from unrealistic data\n",
    "sfo_data_w_flight_class = sfo_data_w_flight_class.loc[sfo_data_w_flight_class['Passenger Count']/sfo_data_w_flight_class['Landing Count'] < 853]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sfo_data_w_flight_class['ratio'] = sfo_data_w_flight_class['Passenger Count']/sfo_data_w_flight_class['Landing Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfo_data_no_date = sfo_data_w_flight_class.drop('Activity Period',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flight_prices = ['Low cost','Legacy','Boutique']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Replacing flight type by factor equivalent\n",
    "# for flight_price in flight_prices:\n",
    "#     sfo_data_w_flight_class.loc[sfo_data_w_flight_class['Price Category Code']==flight_price,'Landing Aircraft Type']=sfo_data_weight['factor'][flight_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfo_data_no_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfo_data_no_date['Landing Aircraft Type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_list_update(dataframe_list,sfo_data_no_date)\n",
    "dataframe_dict['sfo_data_no_date']=sfo_data_no_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Airline name DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I retrieve dataframe of all arilines using SFO_Passanger_statistics_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating SFO airline list\n",
    "sfo_airline_info_df = sfo_passanger_statistics.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drppint unnecessary columns\n",
    "sfo_airline_info_df = sfo_airline_info_df.drop(['Activity Type Code'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering out the airlines, keeping division for domestic and international and price category\n",
    "sfo_airline_info_df = sfo_airline_info_df.drop_duplicates(subset=['Published Airline','GEO Summary','Price Category Code'], keep = 'first') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking NaN\n",
    "for column in sfo_airline_info_df:\n",
    "    null = sfo_airline_info_df[column].isnull().sum()\n",
    "    print(f'{column} has {null} missing values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SFO_airline_info_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_name = sfo_airline_info_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_name = airline_name.drop_duplicates(subset=['Published Airline'], keep = 'first') \n",
    "airline_name = airline_name.drop(['Activity Period','GEO Summary', 'GEO Region','Price Category Code', 'Passenger Count','Operating Airline','Operating Airline IATA Code'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_name = airline_name.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in airline_name:\n",
    "    null = airline_name[column].isnull().sum()\n",
    "    print(f'{column} has {null} missing values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_name = airline_name.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_list_update(dataframe_list,airline_name)\n",
    "dataframe_dict['airline_name']=airline_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Airline Fleet cost DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading airlie fleet data\n",
    "path_to_file3 = os.path.join('Resources','Fleet Data.csv')\n",
    "Fleet_Data_df = pd.read_csv(path_to_file3)\n",
    "Fleet_Data_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping columns total, future, historic, orders as irrelevant, keeping only current, only matters how many airline has now\n",
    "#if airline doesn't have airlplane it is filtered out\n",
    "Fleet_Data_df = Fleet_Data_df.drop(['Total', 'Future', 'Historic', 'Orders','Aircraft Type', 'Unit Cost'],1)\n",
    "Fleet_Data_df = Fleet_Data_df.dropna(subset=['Current'])\n",
    "Fleet_Data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in Fleet_Data_df: \n",
    "    null_nr = Fleet_Data_df[column].isnull().sum()\n",
    "    print(f'{column} has {null_nr} missing data' )\n",
    "    #Fleet_Data_df[column] = Fleet_Data_df[column].fillna()\n",
    "\n",
    "Fleet_Data_df = Fleet_Data_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in Fleet_Data_df: \n",
    "    null_nr = Fleet_Data_df[column].isnull().sum()\n",
    "    \n",
    "    print(f'{column} has {null_nr} missing data' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing $ sign\n",
    "#renaming columns \n",
    "Fleet_Data_df = Fleet_Data_df.rename(columns={'Total Cost (Current)': 'Total Fleet Cost million USD'})\n",
    "\n",
    "#converting str to int and remving $\n",
    "for column in Fleet_Data_df:\n",
    "    if Fleet_Data_df[column].dtype == object:\n",
    "        Fleet_Data_df[column] = Fleet_Data_df[column].str.replace('$', '')\n",
    "        Fleet_Data_df[column] = Fleet_Data_df[column].str.replace(',', '')\n",
    "        \n",
    "#Fleet_Data_df[\"Unit Cost M$\"] = Fleet_Data_df[\"Unit Cost M$\"].astype(int)\n",
    "Fleet_Data_df[\"Total Fleet Cost million USD\"] = Fleet_Data_df[\"Total Fleet Cost million USD\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fleet_Data_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fleet_Data_df = Fleet_Data_df.rename(columns = {'Current': \"Number of Airplanes\"})\n",
    "Fleet_Data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fleet_cost = Fleet_Data_df.groupby(['Airline']).sum()['Total Fleet Cost million USD']\n",
    "#Fleet_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fleet_age_mean = Fleet_Data_df.groupby(['Airline']).mean()['Average Age']\n",
    "#Fleet_age_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fleet_age_std = Fleet_Data_df.groupby(['Airline']).std()['Average Age']\n",
    "#Fleet_age_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_fleet_cost = Fleet_Data_df.groupby(['Airline']).sum()\n",
    "airline_fleet_cost['Fleet Age Average'] = Fleet_age_mean\n",
    "airline_fleet_cost['Fleet Age Distribution'] = Fleet_age_std\n",
    "airline_fleet_cost = airline_fleet_cost.drop(['Average Age'],1)\n",
    "#airline_fleet_cost = airline_fleet_cost.drop(['Unit Cost M$'],1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_fleet_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_fleet_cost=airline_fleet_cost.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_fleet_cost = airline_fleet_cost.rename(columns = {'Airline':'Published Airline'})\n",
    "airline_fleet_cost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_cost_filtered = airline_name.merge(airline_fleet_cost, how = 'left', on = 'Published Airline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_cost_filtered = airline_cost_filtered.dropna()\n",
    "airline_cost_filtered = airline_cost_filtered.reset_index()\n",
    "airline_cost_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_cost_filtered = airline_cost_filtered.drop(['index'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_cost_filtered.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(airline_cost_filtered.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_list_update(dataframe_list,airline_fleet_cost)\n",
    "dataframe_dict['airline_fleet_cost']=airline_fleet_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_list_update(dataframe_list,airline_cost_filtered)\n",
    "dataframe_dict['airline_cost_filtered']=airline_cost_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grand summary table\n",
    "\n",
    "### SFO Data +Airline Fleet cost DB + Airline name DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sfo_data_no_date.reset_index().groupby(['published_airline']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_cost_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_performance = sfo_data_no_date.merge(airline_cost_filtered, how = 'left', on = ['Published Airline','Published Airline IATA Code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_performance_dt = sfo_data_w_flight_class.merge(airline_cost_filtered, how = 'left', on = ['Published Airline','Published Airline IATA Code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_performance_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_performance_dt = airline_performance_dt.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_performance_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_performance = airline_performance.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(airline_performance_dt.groupby('Published Airline').sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(airline_performance.groupby('Published Airline').sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_performance_dt.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_performance.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_list_update(dataframe_list,airline_performance_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_list_update(dataframe_list,airline_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing dataframes to be uploaded to postregSQL\n",
    "#replacing spaces with \"_\"\n",
    "# we use dataframe_list to change all the dataframes\n",
    "\n",
    "for dataframe in dataframe_list:\n",
    "    dataframe.columns = dataframe.columns.str.replace(' ', '_')\n",
    "    dataframe.columns = map(str.lower, dataframe.columns)\n",
    "    display(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_performance_dt = airline_performance_dt.set_index(['published_airline_iata_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_performance = airline_performance.set_index(['published_airline_iata_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_performance_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#airline_performance['ratio'] = airline_performance['passenger_count']/airline_performance['landing_count']\n",
    "#airline_performance.sort_values('ratio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# airline_performance_dt['ratio'] = airline_performance_dt['passenger_count']/airline_performance_dt['landing_count']\n",
    "# airline_performance_dt.sort_values('ratio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing bias from fleet count\n",
    "airline_performance = airline_performance.drop('number_of_airplanes',1)\n",
    "airline_performance_dt = airline_performance_dt.drop('number_of_airplanes',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_performance['landing_aircraft_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in airline_performance.columns:\n",
    "    if airline_performance[column].dtype == object:\n",
    "        airline_performance = pd.get_dummies(airline_performance, columns=[column]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_performance = airline_performance.rename(columns = {'landing_aircraft_type_0.17855239944516121' : 'landing_aircraft_freight',\n",
    "                                                           'landing_aircraft_type_0.6631465954645208' : 'landing_aircraft_passanger' })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_performance = airline_performance.rename(columns = {'price_category_code_1.3' : 'price_category_code_butique', 'price_category_code_0.7': 'price_category_code_low',\n",
    "                                                           'price_category_code_1.0' : 'price_category_code_legacy'}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_performance_dt = airline_performance_dt.rename(columns = {'price_category_code_1.3' : 'price_category_code_butique', 'price_category_code_0.7': 'price_category_code_low',\n",
    "                                                           'price_category_code_1.0' : 'price_category_code_legacy'}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_performance_dt = airline_performance_dt.rename(columns = {'landing_aircraft_type_0.17855239944516121' : 'landing_aircraft_freight',\n",
    "                                                           'landing_aircraft_type_0.6631465954645208' : 'landing_aircraft_passanger' })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_list_update(dataframe_list,airline_performance_dt)\n",
    "dataframe_dict['airline_performance_dt']=airline_performance_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_list_update(dataframe_list,airline_performance)\n",
    "dataframe_dict['airline_performance']=airline_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_save = os.path.join('Resources','airline_performance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_save = os.path.join('Resources','airline_performance_dt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_performance.to_csv(path_to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_performance_dt.to_csv(path_to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_performance.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_name(data):\n",
    "    name =[x for x in globals() if globals()[x] is data][0]\n",
    "    print(\"Dataframe Name is: %s\" % name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display all dataframes\n",
    "\n",
    "for dataframe in dataframe_list:\n",
    "    df_name(dataframe)\n",
    "    display(dataframe)\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uploading the data to postreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#you need to install 'psycopg2' package\n",
    "import psycopg2 as pg\n",
    "from sqlalchemy import create_engine\n",
    "import pandas.io.sql as psql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy  # Package for accessing SQL databases via Python\n",
    "\n",
    "# Connect to database (Note: The package psychopg2 is required for Postgres to work with SQLAlchemy)\n",
    "engine = sqlalchemy.create_engine(f\"postgresql://postgres:{sql_password}@localhost/{target_dbname}\")\n",
    "con = engine.connect()\n",
    "\n",
    "# Verify that there are no existing tables\n",
    "print(engine.table_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table_name1 = 'airline_info'\n",
    "# airline_info_basic_df.to_sql(table_name1, con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uploading dataframes to sql database\n",
    "for key, value in dataframe_dict.items():\n",
    "    try:\n",
    "        start = timeit.timeit()\n",
    "        value.to_sql(key, con)\n",
    "        end = timeit.timeit()\n",
    "        print(f'dataframe {key} uploaded successfully, time: {start - end}')\n",
    "    except(ValueError):\n",
    "        print(f' {key} Table already exist')\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking if data was uploaded to sql correctly\n",
    "print(engine.table_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Readout from postregsql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read out from SQL\n",
    "test_df = pd.read_sql_table('airline_name',engine)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read from sql\n",
    "query = \"SELECT * FROM sfo_landing_statistics\"\n",
    "data = pd.read_sql(query,con)\n",
    "display(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and reading data tables from postregSQL\n",
    "### Creating table airline delay vs. airlline fleet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sql_password = str(input(\"Please provide your sql password :\")) - privided in cell [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = pg.connect(\n",
    "host='localhost',\n",
    "dbname= target_dbname,\n",
    "user='postgres',\n",
    "password= sql_password)\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating table of airline delays on SFO in 2008 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql_operation(command):\n",
    "    try:\n",
    "        cur.execute(command)\n",
    "        conn.commit()\n",
    "    except:\n",
    "        print('Either table already exist or df was not loaded to sql', sys.exc_info()[0], \"\\n must reset connection before iterate block\")\n",
    "        print\n",
    "        cur.close()\n",
    " \n",
    "    return \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Merge Test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating set of commands for sql data base\n",
    "\n",
    "create_sql_combined_delay_airline = \"\"\"\n",
    "\n",
    "SELECT an.published_airline, an.published_airline_iata_code, ads.unique_carrier, ads.carrierdelay_avg \n",
    "INTO sql_combined_delay_airline\n",
    "FROM airline_delay_stat_db as ads\n",
    "LEFT JOIN airline_name as an\n",
    "ON an.published_airline_iata_code = ads.unique_carrier\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "create_delay_airline_vs_cost = \"\"\"\n",
    "\n",
    "SELECT da.published_airline, da.published_airline_iata_code, da.carrierdelay_avg, acf.number_of_airplanes, acf.fleet_age_average\n",
    "INTO delay_airline_vs_cost\n",
    "FROM airline_cost_filtered as acf\n",
    "LEFT JOIN sql_combined_delay_airline as da\n",
    "ON acf.published_airline_iata_code = da.published_airline_iata_code\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "clean_na_from_sql_combined_delay_airline = \"DELETE FROM sql_combined_delay_airline WHERE published_airline IS NULL\"\n",
    "\n",
    "\n",
    "\n",
    "clean_na_from_delay_delay_airline_vs_cost = \"DELETE FROM delay_airline_vs_cost WHERE published_airline IS NULL\"\n",
    "\n",
    "show_df = \"SELECT * FROM sfo_landing_statistics\"\n",
    "\n",
    "table_cleanup = \"\"\"DROP TABLE IF EXISTS sql_combined_delay_airline CASCADE;\n",
    "DROP TABLE IF EXISTS delay_airline_vs_cost CASCADE;\n",
    "DROP TABLE IF EXISTS sfo_airline_total_cost CASCADE;\n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_operation(table_cleanup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    \n",
    "    sql_operation(create_sql_combined_delay_airline)\n",
    "    print('ok1-loaded')\n",
    "    \n",
    "    \n",
    "    sql_operation(create_delay_airline_vs_cost)\n",
    "    print('ok2 - loaded')\n",
    "    \n",
    "    \n",
    "    sql_operation(clean_na_from_sql_combined_delay_airline)\n",
    "    print('ok3 -cleaned')\n",
    "    \n",
    "    sql_operation(clean_na_from_delay_delay_airline_vs_cost)\n",
    "    print('ok5 - cleaned')\n",
    "    \n",
    "    cur.close()\n",
    "except:\n",
    "    print('something wrong, need trouble shoot')\n",
    "    cur.close()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('checking if delay_airline_vs_cost exist')\n",
    "\n",
    "try:\n",
    "    query = \"SELECT * FROM delay_airline_vs_cost\"\n",
    "    delay_airline_vs_cost = pd.read_sql(query,con)\n",
    "    display(delay_airline_vs_cost)\n",
    "except:\n",
    "    print('delay_airline_vs_cost does not exist')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('checking if sql_combined_delay_airline exist')\n",
    "\n",
    "try:\n",
    "    query = \"SELECT * FROM sql_combined_delay_airline\"\n",
    "    sql_combined_delay_airline = pd.read_sql(query,con)\n",
    "    display(sql_combined_delay_airline)\n",
    "except:\n",
    "    print('sql_combined_delay_airline does not exist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#closing connection\n",
    "cur.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Merge Test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = pg.connect(\n",
    "host='localhost',\n",
    "dbname= target_dbname,\n",
    "user='postgres',\n",
    "password= sql_password)\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_sfo_airline_cost = \"\"\"\n",
    "SELECT an.published_airline, an.published_airline_iata_code, afc.number_of_airplanes, afc.total_fleet_cost_million_usd \n",
    "INTO sfo_airline_total_cost\n",
    "FROM airline_fleet_cost as afc\n",
    "INNER JOIN airline_name as an\n",
    "ON an.published_airline = afc.published_airline\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_operation(create_sfo_airline_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#closing connection\n",
    "cur.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfo_airline_total_cost = pd.read_sql_table('sfo_airline_total_cost',engine)\n",
    "sfo_airline_total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_performance = pd.read_sql_table('airline_performance',engine)\n",
    "airline_performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.close ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database cleaning \n",
    "### if things go bad and user wants to clean all sql database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = pg.connect(\n",
    "host='localhost',\n",
    "dbname= target_dbname,\n",
    "user='postgres',\n",
    "password= sql_password)\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erase_command = \"\"\"\n",
    "DROP TABLE IF EXISTS sql_combined_delay_airline CASCADE;\n",
    "DROP TABLE IF EXISTS delay_airline_vs_cost CASCADE;\n",
    "DROP TABLE IF EXISTS delay_airline_from_null CASCADE;\n",
    "DROP TABLE IF EXISTS delay_airline_vs_cost_from_null CASCADE;\n",
    "DROP TABLE IF EXISTS create_sfo_airline_cost CASCADE;\n",
    "DROP TABLE IF EXISTS airline_cost_filtered CASCADE;\n",
    "DROP TABLE IF EXISTS airline_delay_stat_db CASCADE;\n",
    "DROP TABLE IF EXISTS airline_fleet_cost CASCADE;\n",
    "DROP TABLE IF EXISTS airline_name CASCADE;\n",
    "DROP TABLE IF EXISTS airline_performance CASCADE;\n",
    "DROP TABLE IF EXISTS airline_performance_dt CASCADE;\n",
    "DROP TABLE IF EXISTS sfo_airline_total_cost CASCADE;\n",
    "DROP TABLE IF EXISTS sfo_data_no_date CASCADE;\n",
    "DROP TABLE IF EXISTS sfo_landing_statistics CASCADE;\n",
    "DROP TABLE IF EXISTS sfo_passanger_statistics CASCADE;\n",
    "\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erase = input('do you want to clean the data base from tables ? [yes/no] :')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if erase == 'yes':\n",
    "    \n",
    "    #establishing connection\n",
    "    conn = pg.connect(\n",
    "    host='localhost',\n",
    "    dbname= target_dbname,\n",
    "    user='postgres',\n",
    "    password= sql_password)\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    sql_operation(erase_command)\n",
    "    print(engine.table_names())\n",
    "    \n",
    "    \n",
    "    cur.close()\n",
    "    con.close ()\n",
    "    \n",
    "else:\n",
    "    print('ok')\n",
    "    print(engine.table_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
